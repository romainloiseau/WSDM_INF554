{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\romai\\Miniconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "test = pd.read_csv('../output_preprocessed/test_last_transaction.csv')\n",
    "test_features = test[test.columns[2:]]\n",
    "\n",
    "predictions = pd.DataFrame()\n",
    "predictions['msno']=test['msno']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../output_preprocessed/train_last_transaction.csv')\n",
    "train = train[train.columns[1:]]\n",
    "train_features = train[train.columns[1:]]\n",
    "train_labels = train[\"is_churn\"]\n",
    "del train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trans_count</th>\n",
       "      <th>logs_count</th>\n",
       "      <th>city</th>\n",
       "      <th>bd</th>\n",
       "      <th>gender</th>\n",
       "      <th>registered_via</th>\n",
       "      <th>registration_init_time</th>\n",
       "      <th>payment_method_id</th>\n",
       "      <th>payment_plan_days</th>\n",
       "      <th>plan_list_price</th>\n",
       "      <th>...</th>\n",
       "      <th>membership_expire_date</th>\n",
       "      <th>is_cancel</th>\n",
       "      <th>date</th>\n",
       "      <th>num_25</th>\n",
       "      <th>num_50</th>\n",
       "      <th>num_75</th>\n",
       "      <th>num_985</th>\n",
       "      <th>num_100</th>\n",
       "      <th>num_unq</th>\n",
       "      <th>total_secs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20050406.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20170121.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>19799.702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20050407.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20170319.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>281.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20051016.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20161225.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>15845.692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20051102.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20170426.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20170331.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>6171.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20051228.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>477.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20170528.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20170331.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3132.042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   trans_count  logs_count  city    bd  gender  registered_via  \\\n",
       "0            2         0.0  18.0  36.0     2.0             9.0   \n",
       "1           23         1.0  10.0  38.0     1.0             9.0   \n",
       "2           10         0.0  11.0  27.0     2.0             9.0   \n",
       "3            3         5.0  13.0  23.0     2.0             9.0   \n",
       "4            9        17.0   3.0  27.0     1.0             9.0   \n",
       "\n",
       "   registration_init_time  payment_method_id  payment_plan_days  \\\n",
       "0              20050406.0                0.0                0.0   \n",
       "1              20050407.0                0.0                0.0   \n",
       "2              20051016.0                0.0                0.0   \n",
       "3              20051102.0               40.0               30.0   \n",
       "4              20051228.0               38.0               90.0   \n",
       "\n",
       "   plan_list_price     ...      membership_expire_date  is_cancel        date  \\\n",
       "0              0.0     ...                         0.0        0.0  20170121.0   \n",
       "1              0.0     ...                         0.0        0.0  20170319.0   \n",
       "2              0.0     ...                         0.0        0.0  20161225.0   \n",
       "3            149.0     ...                  20170426.0        0.0  20170331.0   \n",
       "4            477.0     ...                  20170528.0        0.0  20170331.0   \n",
       "\n",
       "   num_25  num_50  num_75  num_985  num_100  num_unq  total_secs  \n",
       "0     4.0     0.0     2.0      5.0     76.0     74.0   19799.702  \n",
       "1     0.0     0.0     0.0      0.0      1.0      1.0     281.600  \n",
       "2    61.0    21.0     9.0     11.0     44.0    130.0   15845.692  \n",
       "3    28.0     4.0     5.0      4.0     19.0     51.0    6171.145  \n",
       "4     0.0     0.0     0.0      2.0     11.0     12.0    3132.042  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.076786848149922787"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_labels == 1).sum()/len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['trans_count', 'logs_count', 'city', 'bd', 'gender', 'registered_via',\n",
       "       'registration_init_time', 'payment_method_id', 'payment_plan_days',\n",
       "       'plan_list_price', 'actual_amount_paid', 'is_auto_renew',\n",
       "       'transaction_date', 'membership_expire_date', 'is_cancel', 'date',\n",
       "       'num_25', 'num_50', 'num_75', 'num_985', 'num_100', 'num_unq',\n",
       "       'total_secs'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replacemean(x, t, mean):\n",
    "    if(x < t):\n",
    "        return mean\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\romai\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "mean_registration_init_time = train_features[train_features[\"registration_init_time\"] > 1][\"registration_init_time\"].mean()\n",
    "train_features[\"registration_init_time\"] = train_features[\"registration_init_time\"].apply(lambda x: replacemean(x, 1, mean_registration_init_time))\n",
    "test_features[\"registration_init_time\"] = test_features[\"registration_init_time\"].apply(lambda x: replacemean(x, 1, mean_registration_init_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\romai\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "mean_transaction_date = train_features[train_features[\"transaction_date\"] > 1][\"transaction_date\"].mean()\n",
    "train_features[\"transaction_date\"] = train_features[\"transaction_date\"].apply(lambda x: replacemean(x, 1, mean_transaction_date))\n",
    "test_features[\"transaction_date\"] = test_features[\"transaction_date\"].apply(lambda x: replacemean(x, 1, mean_transaction_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\romai\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "mean_date = train_features[train_features[\"date\"] > 1][\"date\"].mean()\n",
    "train_features[\"date\"] = train_features[\"date\"].apply(lambda x: replacemean(x, 1, mean_date))\n",
    "test_features[\"date\"] = test_features[\"date\"].apply(lambda x: replacemean(x, 1, mean_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\romai\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "cols_to_transform = [\"city\", \"gender\", \"payment_method_id\"]\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(train_features.loc[:][cols_to_transform])\n",
    "\n",
    "ONE_HOT_train = (enc.transform(train_features.loc[:][cols_to_transform]).toarray()).transpose()\n",
    "ONE_HOT_test = (enc.transform(test_features.loc[:][cols_to_transform]).toarray()).transpose()\n",
    "\n",
    "for col in cols_to_transform:\n",
    "    del train_features[col]\n",
    "    del test_features[col]\n",
    "\n",
    "for i in range(0, ONE_HOT_train.shape[0]):\n",
    "    train_features[\"ONE_HOT_\"+str(i)] = ONE_HOT_train[i]\n",
    "    test_features[\"ONE_HOT_\"+str(i)] = ONE_HOT_test[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "norm = Normalizer()\n",
    "norm.fit(train_features)\n",
    "\n",
    "train_features_preprocessed = norm.transform(train_features)\n",
    "test_features_preprocessed = norm.transform(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_logloss(pred_proba, ischurn):\n",
    "    logloss = -((ischurn*np.log(pred_proba)).sum() + ((1 - ischurn)*np.log(1 - pred_proba)).sum())\n",
    "    return (logloss / len(pred_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from xgboost import XGBClassifier\n",
    "# from sklearn import ensemble\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# import lightgbm as lgb\n",
    "\n",
    "# MAX_FOLD = 10\n",
    "# logloss_gbm = 0\n",
    "# logloss_lgbm = 0\n",
    "# logloss_adb = 0\n",
    "# logloss_lg = 0\n",
    "# for i in range(0, MAX_FOLD):\n",
    "    \n",
    "#     #gbm = XGBClassifier(n_estimators=500, learning_rate=0.025, max_depth=4, subsample=0.8, colsample_bytree=1)\n",
    "# #     params = {\n",
    "# #         'learning_rate' : 0.1,\n",
    "# #          'n_estimators' : 1000,\n",
    "# #          'max_depth' : 10,\n",
    "# #          'min_child_weight': 12,\n",
    "# #          'gamma' :10,\n",
    "# #          'subsample':0.8,\n",
    "# #          'colsample_bytree':0.8,\n",
    "# #          'objective': 'binary:logistic',\n",
    "# #          'scale_pos_weight':1,\n",
    "# #          'seed':27\n",
    "# #     }\n",
    "    \n",
    "#     gbm = XGBClassifier(max_delta_step = 1)\n",
    "#     lgbm = lgb.LGBMClassifier()\n",
    "#     adb = ensemble.AdaBoostClassifier()\n",
    "#     lg = LogisticRegression()\n",
    "    \n",
    "#     X_train, X_test, y_train, y_test = train_test_split(train_features_preprocessed, train_labels, test_size = 0.1)\n",
    "#     print(\"COMPUTING FOLD \"+str(i)+\"/\"+str(MAX_FOLD))\n",
    "    \n",
    "#     params = {\n",
    "#         'eta': 0.02, #use 0.002\n",
    "#         'max_depth': 7,\n",
    "#         'objective': 'binary:logistic',\n",
    "#         'eval_metric': 'logloss',\n",
    "#         'seed': i,\n",
    "#         'silent': True\n",
    "#     }\n",
    "#     gbm.fit(X_train, y_train)\n",
    "#     lgbm.fit(X_train, y_train)\n",
    "#     adb.fit(X_train, y_train)\n",
    "#     lg.fit(X_train, y_train)\n",
    "    \n",
    "#     pred_gbm = gbm.predict_proba(X_test)[:,1]\n",
    "#     logloss_gbm_tmp = compute_logloss(pred_gbm, y_test)\n",
    "#     logloss_gbm += logloss_gbm_tmp\n",
    "    \n",
    "#     pred_lgbm = lgbm.predict_proba(X_test)[:,1]\n",
    "#     logloss_lgbm_tmp = compute_logloss(pred_lgbm, y_test)\n",
    "#     logloss_lgbm += logloss_lgbm_tmp\n",
    "        \n",
    "#     pred_adb = adb.predict_proba(X_test)[:,1]\n",
    "#     logloss_adb_tmp = compute_logloss(pred_adb, y_test)\n",
    "#     logloss_adb += logloss_adb_tmp\n",
    "    \n",
    "#     pred_lg = lg.predict_proba(X_test)[:,1]\n",
    "#     logloss_lg_tmp = compute_logloss(pred_lg, y_test)\n",
    "#     logloss_lg += logloss_lg_tmp\n",
    "    \n",
    "#     print(int(10000*logloss_gbm_tmp)/10000,\n",
    "#           int(10000*logloss_lgbm_tmp)/10000,\n",
    "#           int(10000*logloss_lg_tmp)/10000,\n",
    "#           int(10000*logloss_adb_tmp)/10000)\n",
    "    \n",
    "#     print(compute_logloss(np.exp(np.mean([pred_gbm.apply(lambda x: np.log(x)),\\\n",
    "#                                         pred_lgbm.apply(lambda x: np.log(x)),\\\n",
    "#                                         pred_adb.apply(lambda x: np.log(x)),\\\n",
    "#                                         pred_lg.apply(lambda x: np.log(x)),\\\n",
    "#                                         ], axis =0)), y_test))\n",
    "    \n",
    "#     del y_test, X_train, X_test, y_train\n",
    "\n",
    "# print(\"END\")\n",
    "# print(logloss_gbm/MAX_FOLD, logloss_lgbm/MAX_FOLD, logloss_adb/MAX_FOLD, logloss_lg/MAX_FOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn import ensemble\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import lightgbm as lgb\n",
    "\n",
    "gbm = XGBClassifier(max_delta_step = 1)\n",
    "lgbm = lgb.LGBMClassifier()\n",
    "adb = ensemble.AdaBoostClassifier()\n",
    "lg = LogisticRegression()\n",
    "    \n",
    "gbm.fit(train_features_preprocessed, train_labels)\n",
    "lgbm.fit(train_features_preprocessed, train_labels)\n",
    "adb.fit(train_features_preprocessed, train_labels)\n",
    "lg.fit(train_features_preprocessed, train_labels)\n",
    "    \n",
    "pred_gbm = gbm.predict_proba(test_features_preprocessed) \n",
    "pred_lgbm = lgbm.predict_proba(test_features_preprocessed)      \n",
    "pred_adb = adb.predict_proba(test_features_preprocessed)\n",
    "pred_lg = lg.predict_proba(test_features_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k1 = pd.read_csv('../from_kaggle_kernels/kk_pred.csv')\n",
    "k2 = pd.read_csv('../from_kaggle_kernels/submission.csv')\n",
    "k3 = pd.read_csv('../from_kaggle_kernels/xgbsub.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[\"pred_gbm\"] = pred_gbm\n",
    "predictions[\"pred_lgbm\"] = pred_lgbm\n",
    "predictions[\"pred_adb\"] = pred_adb\n",
    "predictions[\"pred_lg\"] = pred_lg\n",
    "\n",
    "predictions['is_churn'] = np.exp(np.mean(\n",
    "        [\n",
    "        k1['is_churn'].apply(lambda x: np.log(x)),\\\n",
    "        k2['is_churn'].apply(lambda x: np.log(x)),\\\n",
    "        k3['is_churn'].apply(lambda x: np.log(x)),\\\n",
    "        predictions[\"pred_gbm\"].apply(lambda x: np.log(x)),\\\n",
    "        predictions[\"pred_lgbm\"].apply(lambda x: np.log(x)),\\\n",
    "        predictions[\"pred_adb\"].apply(lambda x: np.log(x)),\\\n",
    "        predictions[\"pred_lg\"].apply(lambda x: np.log(x)),\\\n",
    "        ], axis =0))\n",
    "\n",
    "del predictions[\"pred_gbm\"]\n",
    "del predictions[\"pred_lgbm\"]\n",
    "del predictions[\"pred_adb\"]\n",
    "del predictions[\"pred_lg\"]\n",
    "\n",
    "predictions.to_csv(\"../output/from_kaggle_kernels_and_calculs.csv\", float_format='%.6f', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
