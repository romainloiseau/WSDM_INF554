{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "from sklearn.decomposition import PCA\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.utils import shuffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../output_preprocessed/test_last_transaction.csv')\n",
    "test_features = test[test.columns[2:]]\n",
    "\n",
    "predictions = pd.DataFrame()\n",
    "predictions['msno']=test['msno']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../output_preprocessed/train_last_transaction.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          1\n",
       "1          1\n",
       "2          1\n",
       "3          1\n",
       "4          1\n",
       "5          1\n",
       "6          1\n",
       "7          1\n",
       "8          1\n",
       "9          1\n",
       "10         1\n",
       "11         1\n",
       "12         1\n",
       "13         1\n",
       "14         1\n",
       "15         1\n",
       "16         1\n",
       "17         1\n",
       "18         1\n",
       "19         1\n",
       "20         1\n",
       "21         1\n",
       "22         1\n",
       "23         1\n",
       "24         1\n",
       "25         1\n",
       "26         1\n",
       "27         1\n",
       "28         1\n",
       "29         1\n",
       "          ..\n",
       "1963861    0\n",
       "1963862    0\n",
       "1963863    0\n",
       "1963864    0\n",
       "1963865    0\n",
       "1963866    0\n",
       "1963867    0\n",
       "1963868    0\n",
       "1963869    0\n",
       "1963870    0\n",
       "1963871    0\n",
       "1963872    0\n",
       "1963873    0\n",
       "1963874    0\n",
       "1963875    0\n",
       "1963876    0\n",
       "1963877    0\n",
       "1963878    0\n",
       "1963879    0\n",
       "1963880    0\n",
       "1963881    0\n",
       "1963882    0\n",
       "1963883    0\n",
       "1963884    0\n",
       "1963885    0\n",
       "1963886    0\n",
       "1963887    0\n",
       "1963888    0\n",
       "1963889    0\n",
       "1963890    0\n",
       "Name: is_churn, Length: 1963891, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.is_churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "desired_apriori=0.10\n",
    "\n",
    "# Get the indices per target value\n",
    "idx_0 = train[train.is_churn == 0].index\n",
    "idx_1 = train[train.is_churn == 1].index\n",
    "\n",
    "\n",
    "\n",
    "# Get original number of records per target value\n",
    "nb_0 = len(train.loc[idx_0])\n",
    "nb_1 = len(train.loc[idx_1])\n",
    "\n",
    "# Calculate the undersampling rate and resulting number of records with target=0\n",
    "undersampling_rate = ((1-desired_apriori)*nb_1)/(nb_0*desired_apriori)\n",
    "undersampled_nb_0 = int(undersampling_rate*nb_0)\n",
    "\n",
    "# Randomly select records with target=0 to get at the desired a priori\n",
    "undersampled_idx = shuffle(idx_0, random_state=37, n_samples=undersampled_nb_0)\n",
    "\n",
    "# Construct list with remaining indices\n",
    "idx_list = list(undersampled_idx) + list(idx_1)\n",
    "\n",
    "# Return undersample data frame\n",
    "train = train.loc[idx_list].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150801\n",
      "1357208\n"
     ]
    }
   ],
   "source": [
    "print(len(train[train.is_churn == 1]))\n",
    "print(len(train[train.is_churn == 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1: 150801\n",
    "0: 1813090"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train[train.columns[1:]]\n",
    "train_features = train[train.columns[1:]]\n",
    "train_labels = train[\"is_churn\"]\n",
    "del train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trans_count</th>\n",
       "      <th>logs_count</th>\n",
       "      <th>city</th>\n",
       "      <th>bd</th>\n",
       "      <th>gender</th>\n",
       "      <th>registered_via</th>\n",
       "      <th>registration_init_time</th>\n",
       "      <th>payment_method_id</th>\n",
       "      <th>payment_plan_days</th>\n",
       "      <th>plan_list_price</th>\n",
       "      <th>...</th>\n",
       "      <th>membership_expire_date</th>\n",
       "      <th>is_cancel</th>\n",
       "      <th>date</th>\n",
       "      <th>num_25</th>\n",
       "      <th>num_50</th>\n",
       "      <th>num_75</th>\n",
       "      <th>num_985</th>\n",
       "      <th>num_100</th>\n",
       "      <th>num_unq</th>\n",
       "      <th>total_secs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20130907.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20170416.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20161029.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964.570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20100413.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20170419.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20170330.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1185.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20130807.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20170425.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20170331.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20161001.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20170430.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20170331.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>5864.276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>19.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20160603.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20170406.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20170330.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1834.225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   trans_count  logs_count  city    bd  gender  registered_via  \\\n",
       "0           28         0.0  13.0  39.0     1.0             9.0   \n",
       "1           27        15.0   5.0  19.0     1.0             9.0   \n",
       "2           29        11.0   1.0   0.0     0.0             7.0   \n",
       "3            7        21.0   1.0   0.0     0.0             7.0   \n",
       "4           10        19.0  15.0   0.0     0.0             4.0   \n",
       "\n",
       "   registration_init_time  payment_method_id  payment_plan_days  \\\n",
       "0              20130907.0               40.0               30.0   \n",
       "1              20100413.0               37.0               30.0   \n",
       "2              20130807.0               41.0               30.0   \n",
       "3              20161001.0               41.0               30.0   \n",
       "4              20160603.0               40.0               30.0   \n",
       "\n",
       "   plan_list_price     ...      membership_expire_date  is_cancel        date  \\\n",
       "0            149.0     ...                  20170416.0        0.0  20161029.0   \n",
       "1            149.0     ...                  20170419.0        0.0  20170330.0   \n",
       "2             99.0     ...                  20170425.0        0.0  20170331.0   \n",
       "3             99.0     ...                  20170430.0        0.0  20170331.0   \n",
       "4            149.0     ...                  20170406.0        0.0  20170330.0   \n",
       "\n",
       "   num_25  num_50  num_75  num_985  num_100  num_unq  total_secs  \n",
       "0     0.0     0.0     0.0      0.0      5.0      5.0     964.570  \n",
       "1     0.0     0.0     1.0      0.0      4.0      1.0    1185.043  \n",
       "2     1.0     0.0     0.0      0.0      0.0      1.0      21.991  \n",
       "3     1.0     0.0     0.0      1.0     26.0     28.0    5864.276  \n",
       "4     0.0     0.0     0.0      1.0      6.0      7.0    1834.225  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10000006631260158"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_labels == 1).sum()/len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['trans_count', 'logs_count', 'city', 'bd', 'gender', 'registered_via',\n",
       "       'registration_init_time', 'payment_method_id', 'payment_plan_days',\n",
       "       'plan_list_price', 'actual_amount_paid', 'is_auto_renew',\n",
       "       'transaction_date', 'membership_expire_date', 'is_cancel', 'date',\n",
       "       'num_25', 'num_50', 'num_75', 'num_985', 'num_100', 'num_unq',\n",
       "       'total_secs'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replacemean(x, t, mean):\n",
    "    if(x < t):\n",
    "        return mean\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "mean_registration_init_time = train_features[train_features[\"registration_init_time\"] > 1][\"registration_init_time\"].mean()\n",
    "train_features[\"registration_init_time\"] = train_features[\"registration_init_time\"].apply(lambda x: replacemean(x, 1, mean_registration_init_time))\n",
    "test_features[\"registration_init_time\"] = test_features[\"registration_init_time\"].apply(lambda x: replacemean(x, 1, mean_registration_init_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "mean_transaction_date = train_features[train_features[\"transaction_date\"] > 1][\"transaction_date\"].mean()\n",
    "train_features[\"transaction_date\"] = train_features[\"transaction_date\"].apply(lambda x: replacemean(x, 1, mean_transaction_date))\n",
    "test_features[\"transaction_date\"] = test_features[\"transaction_date\"].apply(lambda x: replacemean(x, 1, mean_transaction_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "mean_date = train_features[train_features[\"date\"] > 1][\"date\"].mean()\n",
    "train_features[\"date\"] = train_features[\"date\"].apply(lambda x: replacemean(x, 1, mean_date))\n",
    "test_features[\"date\"] = test_features[\"date\"].apply(lambda x: replacemean(x, 1, mean_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "cols_to_transform = [\"city\", \"gender\", \"payment_method_id\"]\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(train_features.loc[:][cols_to_transform])\n",
    "\n",
    "ONE_HOT_train = (enc.transform(train_features.loc[:][cols_to_transform]).toarray()).transpose()\n",
    "ONE_HOT_test = (enc.transform(test_features.loc[:][cols_to_transform]).toarray()).transpose()\n",
    "\n",
    "for col in cols_to_transform:\n",
    "    del train_features[col]\n",
    "    del test_features[col]\n",
    "\n",
    "for i in range(0, ONE_HOT_train.shape[0]):\n",
    "    train_features[\"ONE_HOT_\"+str(i)] = ONE_HOT_train[i]\n",
    "    test_features[\"ONE_HOT_\"+str(i)] = ONE_HOT_test[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "norm = Normalizer()\n",
    "norm.fit(train_features)\n",
    "\n",
    "train_features_preprocessed = norm.transform(train_features)\n",
    "test_features_preprocessed = norm.transform(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_logloss(pred_proba, ischurn):\n",
    "    logloss = -((ischurn*np.log(pred_proba)).sum() + ((1 - ischurn)*np.log(1 - pred_proba)).sum())\n",
    "    return (logloss / len(pred_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Ensemble(object):\n",
    "    def __init__(self, n_splits, stacker, base_models):\n",
    "        self.n_splits = n_splits\n",
    "        self.stacker = stacker\n",
    "        self.base_models = base_models\n",
    "\n",
    "    def fit_predict(self, X, y, T):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        T = np.array(T)\n",
    "\n",
    "        folds = list(StratifiedKFold(n_splits=self.n_splits, random_state=2016).split(X, y))\n",
    "\n",
    "        S_train = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        S_test = np.zeros((T.shape[0], len(self.base_models)))\n",
    "        for i, clf in enumerate(self.base_models):\n",
    "\n",
    "            S_test_i = np.zeros((T.shape[0], self.n_splits))\n",
    "\n",
    "            for j, (train_idx, test_idx) in enumerate(folds):\n",
    "                X_train = X[train_idx]\n",
    "                y_train = y[train_idx]\n",
    "                X_holdout = X[test_idx]\n",
    "                y_holdout = y[test_idx]\n",
    "\n",
    "                print (\"Fit %s fold %d\" % (str(clf).split('(')[0], j+1))\n",
    "                clf.fit(X_train, y_train)\n",
    "#                cross_score = cross_val_score(clf, X_train, y_train, cv=3, scoring='roc_auc')\n",
    "#                print(\"    cross_score: %.5f\" % (cross_score.mean()))\n",
    "                y_pred = clf.predict_proba(X_holdout)[:,1]                \n",
    "                print(gini_normalized(y_holdout,y_pred))\n",
    "                S_train[test_idx, i] = y_pred\n",
    "                S_test_i[:, j] = clf.predict_proba(T)[:,1]\n",
    "            S_test[:, i] = S_test_i.mean(axis=1)\n",
    "\n",
    "#         results = cross_val_score(self.stacker, S_train, y, cv=3, scoring='roc_auc')\n",
    "#         print(\"Stacker score: %.5f\" % (results.mean()))\n",
    "\n",
    "        self.stacker.fit(S_train, y)\n",
    "        res = self.stacker.predict_proba(S_test)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn import ensemble\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "K = 5\n",
    "# kf = KFold(n_splits=K)\n",
    "kf = StratifiedKFold(n_splits=K)\n",
    "\n",
    "#gbm = XGBClassifier(max_delta_step = 1)\n",
    "#gbm.fit(train_features_preprocessed, train_labels)\n",
    "#predictions[\"pred_gbm\"] = gbm.predict_proba(test_features_preprocessed)[:,1]\n",
    "\n",
    "\n",
    "# lgbm = lgb.LGBMClassifier(n_estimatorsobjective='binary')\n",
    "# lgbm.fit(train_features_preprocessed, train_labels)\n",
    "# predictions[\"pred_lgbm\"] = lgbm.predict_proba(test_features_preprocessed)[:,1]\n",
    "\n",
    "\n",
    "\n",
    "#adb = ensemble.AdaBoostClassifier()\n",
    "#adb.fit(train_features_preprocessed, train_labels)\n",
    "#predictions[\"pred_adb\"] = adb.predict_proba(test_features_preprocessed)[:,1]\n",
    "\n",
    "\n",
    "#lg = LogisticRegression()\n",
    "#lg.fit(train_features_preprocessed, train_labels)\n",
    "#predictions[\"pred_lg\"] = lg.predict_proba(test_features_preprocessed)[:,1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "///////////////////////////////////////////////////////////////////////////////\n",
      "0.0843943028925\n"
     ]
    }
   ],
   "source": [
    "#max_depth=6, subsample=0.8, colsample_bytree=0.8, reg_alpha =2, reg_lambda = 6,\n",
    "\n",
    "for est in [1000]:\n",
    "    for et in [0.005]:\n",
    "        for depth in [-1]:\n",
    "            for col in [0.6,0.8,0.9,1]:\n",
    "                for sub in [0.6,0.8,0.9,1]:\n",
    "                    print(\"///////////////////////////////////////////////////////////////////////////////\")\n",
    "                    lgbm = lgb.LGBMClassifier(n_estimators=est, learning_rate = et , max_depth=depth, subsamble = sub , colsample_bytree=col, objective='binary')\n",
    "                    targets = np.asarray([0.]*test.shape[0])\n",
    "                    for train_index,test_index in kf.split(train_features_preprocessed,train_labels):\n",
    "                        X_train, y_train = train_features_preprocessed[train_index].copy(),train_labels[train_index].copy()\n",
    "                        X_test, y_test = train_features_preprocessed[test_index].copy(),train_labels[test_index].copy()\n",
    "                        fit_lgbm = lgbm.fit(X_train, y_train,eval_metric='')\n",
    "                        y_predict=fit_lgbm.predict_proba(X_test)\n",
    "                        score=compute_logloss(y_predict[:,1],y_test.values)\n",
    "                        print(score)\n",
    "                        targets += fit_lgbm.predict_proba(test_features_preprocessed)[:,1]\n",
    "                        del y_test, X_train, X_test, y_train\n",
    "                    targets /=K\n",
    "                    test_target = pd.DataFrame()\n",
    "                    test_target['msno']=test['msno']\n",
    "                    test_target['is_churn']=targets\n",
    "                    test_target.to_csv('../output/output_LGB_est'+str(est)+'_lr'+str(et)+'_maxdepth'+str(depth)+'_col'+str(col)+'_sub'+str(sub)+'.csv', index=False)\n",
    "\n",
    "#predictions.to_csv(\"../output/from_kaggle_kernels_and_calculs.csv\", float_format='%.6f', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cl1 = lgb.LGBMClassifier(n_estimators=1000, learning_rate =0.005 , max_depth=-1,objective='binary')\n",
    "lr1 = LogisticRegression()\n",
    "stack = Ensemble(n_splits=5,\n",
    "        stacker = lr1,\n",
    "        base_models = (cl1))\n",
    "\n",
    "targets = stack.fit_predict(X,y,test.drop(['id'],axis=1))[:,1]\n",
    "test_target = pd.DataFrame()\n",
    "test_target['id']=test['id']\n",
    "test_target['target']=targets\n",
    "# test_target.to_csv('./output/output_LGB_showoff.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "///////////////////////////////////////////////////////////////////////////////\n",
    "est=1000 et=0.005 depth=-1\n",
    "0.0832268324013\n",
    "0.0840225550256\n",
    "0.130625156578\n",
    "0.136549348377\n",
    "0.136210738066\n",
    "///////////////////////////////////////////////////////////////////////////////\n",
    "est=1000 et=0.005 depth=7\n",
    "0.0831035400493\n",
    "0.0839660360624\n",
    "0.132396293088\n",
    "0.138398769378\n",
    "0.138883725537\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
